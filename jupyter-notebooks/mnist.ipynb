{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f06ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf68ff7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import argparse\n",
    "import os.path as osp\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from utils.get_subgraph import *\n",
    "import torch.nn.functional as F\n",
    "import networkx as nx\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.data import Batch\n",
    "from gnn import MNISTNet\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.datasets import MNISTSuperpixels\n",
    "from utils import *\n",
    "from explainers import *\n",
    "from utils.dataset import MNISTTransform\n",
    "_vis_dict_ = {\n",
    "    'MutagNet': {'node_size': 400, 'linewidths': 1, 'font_size': 10, 'width': 3},\n",
    "    'Tox21Net': {'node_size': 400, 'linewidths': 1, 'font_size': 10, 'width': 3},\n",
    "    'BA3MotifNet': {'node_size': 300, 'linewidths': 1, 'font_size': 10, 'width': 3},\n",
    "    'TR3MotifNet': {'node_size': 300, 'linewidths': 1, 'font_size': 10, 'width': 5},\n",
    "    'defult': {'node_size': 150, 'linewidths': 1, 'font_size': 10, 'width': 0.5}\n",
    "}\n",
    "vis_dict = _vis_dict_['defult']\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "batch_size =  32\n",
    "data_path = 'data/MNIST'\n",
    "transform = MNISTTransform(cat=False, max_value=9)\n",
    "# transform = T.Cartesian(cat=False, max_value=9)\n",
    "test_dataset = MNISTSuperpixels(data_path, False, transform=transform)\n",
    "test_loader = DataLoader(test_dataset[:1000], batch_size=batch_size, shuffle=False)\n",
    "\n",
    "n_loop = 1\n",
    "edge_ratio=0.2\n",
    "f = 'NEW_MNIST_FINAL_NoOverload'#'NEW_MNIST_ablation_cts'\n",
    "path = \"param/gnns/mnist_net.pt\"\n",
    "generative_model_path = 'param/cg/%s/generator/best.pkl' % f\n",
    "G = torch.load(generative_model_path, map_location=device).cpu().to(device)\n",
    "gnn = torch.load(path).to(device)\n",
    "\n",
    "def gen_mnist_attr(edge_index, pos):\n",
    "    assert pos is not None\n",
    "    max_value = 9\n",
    "\n",
    "    (row, col) = edge_index\n",
    "\n",
    "    cart = pos[col] - pos[row]\n",
    "    cart = cart.view(-1, 1) if cart.dim() == 1 else cart\n",
    "    cart = cart / (2 * max_value) + 0.5\n",
    "\n",
    "    return cart\n",
    "\n",
    "Explainers = {\n",
    "    0: RandomCaster,\n",
    "    1: SAExplainer,\n",
    "    2: IGExplainer,\n",
    "    3: DeepLIFTExplainer,\n",
    "    4: GradCam,\n",
    "    5: GNNExplainer,\n",
    "    6: CXplainer,\n",
    "    # 7: PGExplainer,\n",
    "    8: PGMExplainer,\n",
    "    9: Screener,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a414ca6",
   "metadata": {},
   "source": [
    "## Stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbaf39fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = 0.\n",
    "num_edges = 0.\n",
    "for g in tqdm(iter(test_loader), total=len(test_loader)):\n",
    "    num_nodes += g.num_nodes\n",
    "    num_edges += g.num_edges\n",
    "print(\"Average #Nodes {:.4f}\".format(num_nodes/len(test_loader.dataset)))\n",
    "print(\"Average #Edges {:.4f}\".format(num_edges/len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9062c5f",
   "metadata": {},
   "source": [
    "### CG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666a6ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(1)\n",
    "ID_ACC = torch.tensor([]).to(device)\n",
    "OOD_ACC = torch.tensor([]).to(device)\n",
    "with torch.no_grad():\n",
    "    G.eval()\n",
    "    ID_perf = torch.tensor([]).to(device)\n",
    "    for _g in tqdm(iter(test_loader), total=len(test_loader)):\n",
    "        g = _g.clone()\n",
    "        g.to(device)\n",
    "        pos = g.pos\n",
    "        broken_edge_index, broken_edge_attr, out_edge_ratio = get_mnist_ground_truth_graph(g)\n",
    "        mu, log_var, z = G.encode(\n",
    "            x=g.x, in_edge_index=broken_edge_index, \n",
    "            in_edge_attr=broken_edge_attr\n",
    "            )\n",
    "        _, _, cond_z = G.encode(\n",
    "            x=g.x, in_edge_index=g.edge_index, \n",
    "            in_edge_attr=g.edge_attr\n",
    "            )\n",
    "        z = torch.cat([z, cond_z], dim=1)\n",
    "        for _ in range(3):\n",
    "            fake_edge_index, fake_edge_prob, fake_edge_attr, _ = \\\n",
    "                G.fill(\n",
    "                    z=z, preserved_edge_index=broken_edge_index, \n",
    "                    preserved_edge_ratio=out_edge_ratio,\n",
    "                    batch=g.batch, pos=pos, neg_edge_index=None, threshold=False\n",
    "                    )\n",
    "            # print(fake_edge_prob.min(), fake_edge_prob.max())\n",
    "            relabel_x, relabel_edge_index, relabel_batch, relabel_pos = relabel(g.x, fake_edge_index, g.batch, pos)\n",
    "            new_g = Batch(batch=relabel_batch, x=relabel_x, edge_index=relabel_edge_index, edge_attr=fake_edge_attr, pos=relabel_pos)\n",
    "            readout = gnn(data=new_g)\n",
    "            id_acc = (g.y == readout.argmax(dim=1)).view(-1).float()\n",
    "            ID_perf = torch.cat([ID_perf, id_acc])\n",
    "\n",
    "    ID_perf = ID_perf.mean().item() * 100\n",
    "ID_perf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd51d507",
   "metadata": {},
   "source": [
    "## CG \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd17db10",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _g in tqdm(iter(test_loader), total=len(test_loader)):\n",
    "    g = _g.clone()\n",
    "    g.to(device)\n",
    "    pos = g.pos.clone()\n",
    "    broken_edge_index, broken_edge_attr, out_edge_ratio = get_mnist_ground_truth_graph(g)\n",
    "    \n",
    "    # computer the acc of ground truth graph\n",
    "    relabel_x_gd, relabel_edge_index_gd, relabel_batch_gd, relabel_pos_gd = relabel(g.x, broken_edge_index, g.batch, pos=pos)\n",
    "    _g_gd = Batch(\n",
    "        batch=relabel_batch_gd, x=relabel_x_gd, \n",
    "        edge_index=relabel_edge_index_gd, \n",
    "        edge_attr=broken_edge_attr, pos=relabel_pos_gd, y=g.y)\n",
    "    readout = gnn(_g_gd)\n",
    "    ood_acc = (_g_gd.y == readout.argmax(dim=1)).view(-1).float()\n",
    "    OOD_ACC = torch.cat([OOD_ACC, ood_acc])\n",
    "        \n",
    "OOD_ACC = OOD_ACC.mean().item() * 100\n",
    "print(\"OOD_ACC:\", OOD_ACC)\n",
    "print('VAL value: {:.3f}'.format(ID_perf - OOD_ACC))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185cd190",
   "metadata": {},
   "source": [
    "### Fidelity\n",
    "\n",
    "Broken graph ratio: 0.2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b816697",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(0)\n",
    "generative_model_path = 'param/cg/%s/generator/best.pkl' % f\n",
    "test_loader = DataLoader(test_dataset[:1000], batch_size=1, shuffle=False)\n",
    "G = torch.load(generative_model_path, map_location=device).cpu().to(device)\n",
    "gnn = torch.load(\"param/gnns/mnist_net.pt\").to(device)\n",
    "ID_ACC = torch.tensor([]).to(device)\n",
    "OOD_ACC = torch.tensor([]).to(device)\n",
    "fid_id = []\n",
    "fid_ood = []\n",
    "for _g in tqdm(iter(test_loader), total=len(test_loader)):\n",
    "    g = _g.clone()\n",
    "    g.to(device)\n",
    "    pos = g.pos\n",
    "    Y_ori = gnn(g.clone()).softmax(dim=1).detach().cpu().numpy()[0]\n",
    "    broken_edge_index, broken_edge_attr, out_edge_ratio = get_broken_graph(g, edge_ratio, connectivity=False)\n",
    "    \n",
    "    # for broken graph\n",
    "    relabel_x_gd, relabel_edge_index_gd, relabel_batch_gd, relabel_pos_gd = relabel(g.x, broken_edge_index, g.batch, pos=pos)\n",
    "    _g_gd = Batch(batch=relabel_batch_gd, \n",
    "                  x=relabel_x_gd, edge_index=relabel_edge_index_gd, \n",
    "                  edge_attr=broken_edge_attr, pos=relabel_pos_gd, y=g.y)\n",
    "    readout = gnn(_g_gd)\n",
    "    Y_gs = readout.softmax(dim=1).detach().cpu().numpy()[0]\n",
    "    # for counterfactual generated graph\n",
    "    mu, log_var, z = G.encode(x=g.x, in_edge_index=broken_edge_index, in_edge_attr=broken_edge_attr)\n",
    "    _, _, cond_z = G.encode(\n",
    "                    x=g.x, in_edge_index=g.edge_index, \n",
    "                    in_edge_attr=g.edge_attr\n",
    "                    )\n",
    "    z = torch.cat([z, cond_z], dim=1)\n",
    "    Y_g_hat_mt = []\n",
    "    for _ in range(20):\n",
    "        fake_edge_index, fake_edge_prob, fake_edge_attr, _ = \\\n",
    "            G.fill(z=z, preserved_edge_index=broken_edge_index, preserved_edge_ratio=out_edge_ratio,\n",
    "                        batch=g.batch, pos=pos,neg_edge_index=None, threshold=False)\n",
    "\n",
    "        relabel_x, relabel_edge_index, relabel_batch, relabel_pos = relabel(g.x, fake_edge_index, g.batch, pos=pos)\n",
    "        _g = Batch(batch=relabel_batch, x=relabel_x, edge_index=relabel_edge_index, edge_attr=fake_edge_attr, pos=relabel_pos, y=g.y)\n",
    "        readout = gnn(_g)\n",
    "        Y_g_hat_mt.append(readout.softmax(dim=1).detach().cpu().numpy()[0])\n",
    "    \n",
    "    Y_g_hat_mt = np.array(Y_g_hat_mt).mean(axis=0)\n",
    "    fid_id.append(pow(Y_g_hat_mt-Y_ori, 2).sum())\n",
    "    fid_ood.append(pow(Y_gs-Y_ori, 2).sum())\n",
    "    \n",
    "fid_id = torch.tensor(fid_id)\n",
    "fid_ood = torch.tensor(fid_ood)\n",
    "print('FID ID value: {:.3f}'.format(fid_id.mean()))\n",
    "print('FID OOD value: {:.3f}'.format(fid_ood.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96289e6",
   "metadata": {},
   "source": [
    "## Random \n",
    "\n",
    "### Validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b619e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from module.random_gen import RandomGenerator\n",
    "random = RandomGenerator()\n",
    "\n",
    "for i in range(3):\n",
    "    All_Random_ACC = []\n",
    "    Random_ACC = torch.tensor([]).to(device)\n",
    "    for ori_g in tqdm(iter(test_loader), total=len(test_loader)):\n",
    "        g = ori_g.clone()\n",
    "        g.to(device)\n",
    "        broken_edge_index, broken_edge_attr, out_edge_ratio = get_mnist_ground_truth_graph(g)\n",
    "        tmp_g = g.clone()\n",
    "        tmp_g.edge_index = broken_edge_index\n",
    "        tmp_g.edge_attr = broken_edge_attr\n",
    "        filled_g = random.fill(tmp_g, out_edge_ratio)\n",
    "        filled_x, filled_edge_index, filled_batch, filled_pos = relabel(filled_g.x, filled_g.edge_index, filled_g.batch, pos=tmp_g.pos)\n",
    "        filled_edge_attr = gen_mnist_attr(filled_g.edge_index, g.pos)\n",
    "        relabel_filled_g = Batch(batch=filled_batch, \n",
    "                                  x=filled_x, edge_index=filled_edge_index, \n",
    "                                  edge_attr=filled_edge_attr, pos=filled_pos, y=g.y)\n",
    "        readout = gnn(data=relabel_filled_g)\n",
    "        random_acc = (g.y == readout.argmax(dim=1)).view(-1).float()\n",
    "        Random_ACC = torch.cat([Random_ACC, random_acc])\n",
    "    Random_ACC = Random_ACC.mean().item() * 100\n",
    "    All_Random_ACC.append(Random_ACC)\n",
    "All_Random_ACC = torch.tensor(All_Random_ACC)\n",
    "print('ID  Max ACC {:.2f}  Mean ACC {:.2f}'.format(All_Random_ACC.max(), All_Random_ACC.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf447c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('VAL value: {:.3f}'.format(All_Random_ACC.mean() - 40.8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52067d29",
   "metadata": {},
   "source": [
    "### Fidelity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e5840d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from module.random_gen import RandomGenerator\n",
    "random = RandomGenerator()\n",
    "fid_id = []\n",
    "for ori_g in tqdm(iter(test_loader), total=len(test_loader)):\n",
    "    g = ori_g.clone()\n",
    "    g.to(device)\n",
    "    Y_ori = gnn(data=g).softmax(dim=1).detach().cpu().numpy()[0]\n",
    "    \n",
    "    g = ori_g.clone()\n",
    "    Y_g_hat_mt = []\n",
    "    \n",
    "    broken_edge_index, broken_edge_attr, out_edge_ratio = get_broken_graph(g, 0.2, connectivity=False)\n",
    "    tmp_g = g.clone()\n",
    "    tmp_g.edge_index = broken_edge_index\n",
    "    tmp_g.edge_attr = broken_edge_attr\n",
    "    filled_g = random.fill(tmp_g, out_edge_ratio)\n",
    "    filled_x, filled_edge_index, filled_batch, filled_pos = relabel(filled_g.x, filled_g.edge_index, filled_g.batch, pos=tmp_g.pos)\n",
    "    filled_edge_attr = gen_mnist_attr(filled_g.edge_index, g.pos)\n",
    "    relabel_filled_g = Batch(batch=filled_batch, \n",
    "                              x=filled_x, edge_index=filled_edge_index, \n",
    "                              edge_attr=filled_edge_attr, pos=filled_pos, y=g.y)\n",
    "    relabel_filled_g.to(device)\n",
    "    readout = gnn(data=relabel_filled_g)\n",
    "\n",
    "    Y_g_hat = readout.softmax(dim=1).detach().cpu().numpy()[0]\n",
    "    Y_g_hat_mt.append(Y_g_hat)\n",
    "    \n",
    "    Y_g_hat_mt = np.array(Y_g_hat_mt).mean(axis=0)\n",
    "    fid_id.append(pow(Y_g_hat_mt-Y_ori, 2).sum())\n",
    "    \n",
    "fid_id = torch.tensor(fid_id)\n",
    "print('FID ID value: {:.3f}'.format(fid_id.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452764e9",
   "metadata": {},
   "source": [
    "## VGAE \n",
    "\n",
    "### Validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4655e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgae = torch.load(\"param/vgae/mnist.pt\").to(device)\n",
    "ID_ACC = torch.tensor([]).to(device)\n",
    "for _ in range(1):\n",
    "    for ori_g in tqdm(iter(test_loader), total=len(test_loader)):\n",
    "        g = ori_g.clone()\n",
    "        g.to(device)\n",
    "        broken_edge_index, broken_edge_attr, out_edge_ratio = get_mnist_ground_truth_graph(g)\n",
    "        relabel_x, relabel_edge_index, relabel_batch, _ = relabel(g.x, broken_edge_index, g.batch, g.pos)\n",
    "        z = vgae.encode(g.x, relabel_edge_index, broken_edge_attr)\n",
    "        num_neg_samples = int((1-out_edge_ratio) * g.num_edges)\n",
    "        neg_candidates = negative_sampling(broken_edge_index, g.num_nodes, 3 * num_neg_samples)\n",
    "        prob = vgae.decode(z, neg_candidates)\n",
    "        neg_idx = torch.argsort(-prob)[:num_neg_samples]\n",
    "        fake_edge_index = torch.cat([broken_edge_index, neg_candidates[:, neg_idx]], dim=1)\n",
    "        fake_edge_attr = torch.ones((fake_edge_index.size(1), 1)).to(device)\n",
    "        \n",
    "        filled_x, filled_edge_index, filled_batch, filled_pos = relabel(g.x, fake_edge_index, g.batch, pos=g.pos)\n",
    "        filled_edge_attr = gen_mnist_attr(fake_edge_index, g.pos)\n",
    "        relabel_filled_g = Batch(batch=filled_batch, \n",
    "                                  x=filled_x, edge_index=filled_edge_index, \n",
    "                                  edge_attr=filled_edge_attr, pos=filled_pos, y=g.y).to(device)\n",
    "        readout = gnn(data=relabel_filled_g)\n",
    "        id_acc = (g.y == readout.argmax(dim=1)).view(-1).float() * 100\n",
    "        ID_ACC = torch.cat([ID_ACC, id_acc])\n",
    "        \n",
    "print('ID   Mean ACC {:.2f}'.format(ID_ACC.mean()))\n",
    "print('VAL value: {:.3f}'.format(ID_ACC.mean()- 40.8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fea076",
   "metadata": {},
   "source": [
    "### Fidelity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb58e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fid_id = []\n",
    "vgae = torch.load(\"param/vgae/mnist.pt\").to(device)\n",
    "for ori_g in tqdm(iter(test_loader), total=len(test_loader)):\n",
    "    g = ori_g.clone()\n",
    "    g.to(device)\n",
    "    readout = gnn(data=g)\n",
    "    g = ori_g.clone().to(device)\n",
    "    Y_ori = readout.softmax(dim=1).detach().cpu().numpy()[0]\n",
    "    Y_g_hat_mt = []\n",
    "    \n",
    "    broken_edge_index, broken_edge_attr, out_edge_ratio = get_broken_graph(g, 0.2, connectivity=False)\n",
    "    relabel_x, relabel_edge_index, relabel_batch, _ = relabel(g.x, broken_edge_index, g.batch, None)\n",
    "    z = vgae.encode(g.x, relabel_edge_index, broken_edge_attr)\n",
    "    num_neg_samples = int((1-out_edge_ratio) * g.num_edges)\n",
    "    neg_candidates = negative_sampling(broken_edge_index, g.num_nodes, 2 * num_neg_samples)\n",
    "    prob = vgae.decode(z, neg_candidates)\n",
    "    neg_idx = torch.argsort(-prob)[:num_neg_samples]\n",
    "    fake_edge_index = torch.cat([broken_edge_index, neg_candidates[:, neg_idx]], dim=1)\n",
    "    fake_edge_attr = torch.ones((fake_edge_index.size(1), 1)).to(device)\n",
    "    filled_x, filled_edge_index, filled_batch, filled_pos = relabel(g.x, fake_edge_index, g.batch, pos=g.pos)\n",
    "    filled_edge_attr = gen_mnist_attr(fake_edge_index, g.pos)\n",
    "    relabel_filled_g = Batch(batch=filled_batch, \n",
    "                              x=filled_x, edge_index=filled_edge_index, \n",
    "                              edge_attr=filled_edge_attr, pos=filled_pos, y=g.y).to(device)\n",
    "    readout = gnn(data=relabel_filled_g)\n",
    "    Y_g_hat = readout.softmax(dim=1).detach().cpu().numpy()[0]\n",
    "    Y_g_hat_mt.append(Y_g_hat)\n",
    "    \n",
    "    Y_g_hat_mt = np.array(Y_g_hat_mt).mean(axis=0)\n",
    "    if np.isnan(pow(Y_g_hat_mt-Y_ori, 2).sum()):\n",
    "        print(Y_g_hat_mt, Y_ori)\n",
    "    else:\n",
    "        fid_id.append(pow(Y_g_hat_mt-Y_ori, 2).sum())\n",
    "    \n",
    "fid_id = torch.tensor(fid_id)\n",
    "print('FID ID value: {:.3f}'.format(fid_id.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0feed6",
   "metadata": {},
   "source": [
    "### For Explainers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b6b93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ratio_list=[0.4]\n",
    "for ori_g in tqdm(iter(test_loader), total=len(test_loader)):\n",
    "    g = ori_g.clone()\n",
    "    g.to(device)\n",
    "    print(g)\n",
    "    print(gnn.get_graph_rep(g).size())\n",
    "    SA = Explainers[1](gnn_model_path=path, gen_model_path=generative_model_path)\n",
    "    \n",
    "    g = ori_g.clone()\n",
    "    g.to(device)\n",
    "    SA.explain_graph(g)\n",
    "    \n",
    "    ood_acc, ood_prob = SA.evaluate_acc(top_ratio_list)\n",
    "    id_acc, id_prob, _ = SA.evaluate_CounterSup_acc(top_ratio_list)\n",
    "    precision = SA.evaluate_precision(topk=20)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f560c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainers_id = [1]\n",
    "top_ratio_list = [edge_ratio]\n",
    "explainers = [Explainers[i](gnn_model_path=path, gen_model_path=generative_model_path) for i in explainers_id]\n",
    "\n",
    "seq_precision = []\n",
    "seq_ood_acc = []\n",
    "seq_id_acc = []\n",
    "seq_ood_sp = []\n",
    "seq_id_sp = []\n",
    "\n",
    "for e in explainers:\n",
    "    print(e.name)\n",
    "    id_acc_logger = []\n",
    "    ood_acc_logger = []\n",
    "    precision5_logger = []\n",
    "    cnt = 0\n",
    "    for g in tqdm(iter(test_loader), total=len(test_loader)):\n",
    "        g.to(device)\n",
    "        e.explain_graph(g)#, large_scale=True, C=5)\n",
    "        ood_acc, ood_prob = e.evaluate_acc(top_ratio_list)\n",
    "        id_acc, id_prob, _ = e.evaluate_CounterSup_acc(top_ratio_list)\n",
    "        precision = e.evaluate_precision(topk=50)\n",
    "        precision5_logger.append(precision)\n",
    "        \n",
    "        ood_acc_logger.append(float(ood_acc[0][0]))\n",
    "        id_acc_logger.append(float(id_acc[0][0]))\n",
    "    ood_acc_spearson = np.corrcoef(precision5_logger, ood_acc_logger)[0, -1] # scipy.stats.spearmanr(precision5_logger, ood_acc_logger)[0]\n",
    "    id_acc_spearson = np.corrcoef(precision5_logger, id_acc_logger)[0, -1] # scipy.stats.spearmanr(precision5_logger, id_acc_logger)[0]\n",
    "    \n",
    "    seq_precision.append(np.array(precision5_logger).mean())\n",
    "    seq_ood_acc.append(np.array(ood_acc_logger).mean())\n",
    "    seq_id_acc.append(np.array(id_acc_logger).mean())\n",
    "    seq_ood_sp.append(ood_acc_spearson)\n",
    "    seq_id_sp.append(id_acc_spearson)\n",
    "    \n",
    "    print(\"w.r.t Precision\")\n",
    "    print(\"%.4f\" % seq_precision[-1])\n",
    "    \n",
    "    print(\"w.r.t OOD ACC\")\n",
    "    print(\"%.4f\" % seq_ood_acc[-1])\n",
    "    \n",
    "    print(\"w.r.t ID ACC\")\n",
    "    print(\"%.4f\" % seq_id_acc[-1])\n",
    "    \n",
    "    print(\"w.r.t PearsonC\")\n",
    "    print('Before Counterfactual Infilling, PearsonC: %.4f' % seq_ood_sp[-1])\n",
    "    print('After Counterfactual Infilling, PearsonC: %.4f' % seq_id_sp[-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
